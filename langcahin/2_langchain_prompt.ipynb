{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4470f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate,load_prompt, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d812a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4e3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model='gpt-4', temperature=1.5, max_completion_tokens=100)\n",
    "template= PromptTemplate(\n",
    "    template=\"what is capital of {country}?\",\n",
    "    input_variables= [\"country\"],\n",
    "    validate_template= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97632e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= template.invoke({\"country\": \"India\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb0e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='what is capital of India?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d696148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res= model.invoke(prompt)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c7fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt generator\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "Explanation Style: {style_input}  \n",
    "Explanation Length: {length_input}  \n",
    "1. Mathematical Details:  \n",
    "   - Include relevant mathematical equations if present in the paper.  \n",
    "   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \n",
    "2. Analogies:  \n",
    "   - Use relatable analogies to simplify complex ideas.  \n",
    "If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.  \n",
    "Ensure the summary is clear, accurate, and aligned with the provided style and length.\n",
    "\"\"\",\n",
    "input_variables=['paper_input', 'style_input','length_input'],\n",
    "validate_template=True\n",
    ")\n",
    "\n",
    "template.save('template.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "233800f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now can directly load the template\n",
    "prompt= load_prompt('template.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd504ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The paper 'A Comprehensive Study on Quantum Computing' conducts an expanse review in tension of introducing concepts like the mathematical representation of a quantum ypPac, error rates traveled during computation, trials, successes, and superposition operating mechanisms of still nanict alignment usage examples, trial many applications each STATE\\tdirections\\tq - Word oriented • ‘received,’ Phone '+ baking invitations…\\n\\nIt succinctly details several discriminating yet pivotal partners_Rowcline/light estimation Metrics Catag tables characteristics ‘G391 Communication Other hit simulated\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can chain prompt with model so that only need one invoke call\n",
    "chain= prompt | model\n",
    "\n",
    "res= chain.invoke({\n",
    "    \"paper_input\": \"A Comprehensive Study on Quantum Computing\",\n",
    "    \"style_input\": \"Technical and detailed\",\n",
    "    \"length_input\": \"Concise\"\n",
    "})\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be9bfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1129d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f034e429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Hello! How can I assist you today?\n",
      "AI:  2 multiplied by 5 is equal to 10.\n",
      "AI:  Adding 10 to the result of 2 multiplied by 5 (which is 10) gives you a total of 20.\n",
      "['hi', 'Hello! How can I assist you today?', 'multiply 2 and 5', '2 multiplied by 5 is equal to 10.', 'now add 10', 'Adding 10 to the result of 2 multiplied by 5 (which is 10) gives you a total of 20.', 'exit']\n"
     ]
    }
   ],
   "source": [
    "chat_history= []\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    chat_history.append(user_input)\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    result = model.invoke(chat_history)\n",
    "    chat_history.append(result.content)\n",
    "    print(\"AI: \",result.content)\n",
    "\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd6de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me about LangChain', additional_kwargs={}, response_metadata={}), AIMessage(content='LangChain is a decentralized language learning platform that leverages blockchain technology to connect language learners with native speakers around the world. Users can practice their language skills through video calls, messaging, and other interactive features. The platform aims to provide a more personalized and effective way for users to learn and practice languages in a global community.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "#messages\n",
    "messages=[\n",
    "    SystemMessage(content='You are a helpful assistant'),\n",
    "    HumanMessage(content='Tell me about LangChain')\n",
    "]\n",
    "result = model.invoke(messages)\n",
    "messages.append(AIMessage(content=result.content))\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2dce592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Hello! How can I assist you today?\n",
      "AI:  The product of 2 multiplied by 9 is 18.\n",
      "AI:  Adding 99 to 18, the result is 117.\n",
      "[SystemMessage(content='You are a helpful AI assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='multiply 2 with 9', additional_kwargs={}, response_metadata={}), AIMessage(content='The product of 2 multiplied by 9 is 18.', additional_kwargs={}, response_metadata={}), HumanMessage(content='now add 99', additional_kwargs={}, response_metadata={}), AIMessage(content='Adding 99 to 18, the result is 117.', additional_kwargs={}, response_metadata={}), HumanMessage(content='exit', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content='You are a helpful AI assistant')\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    result = model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=result.content))\n",
    "    print(\"AI: \",result.content)\n",
    "\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bed6512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful cricket expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain in simple terms, what is Dusra', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# chat prompt template\n",
    "\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful {domain} expert'),\n",
    "    ('human', 'Explain in simple terms, what is {topic}')\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({'domain':'cricket','topic':'Dusra'})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2114d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HumanMessage(content=\"I want to request a refund for my order #12345.\")\\n', 'AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")']\n",
      "messages=[SystemMessage(content='You are a helpful customer support agent', additional_kwargs={}, response_metadata={}), HumanMessage(content='HumanMessage(content=\"I want to request a refund for my order #12345.\")\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")', additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is my refund', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# message placeholder\n",
    "\n",
    "\n",
    "chat_template = ChatPromptTemplate([ # chat template\n",
    "    ('system','You are a helpful customer support agent'),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human','{query}')\n",
    "])\n",
    "\n",
    "chat_history = []\n",
    "with open('chat_history.txt') as f: # load chat history\n",
    "    chat_history.extend(f.readlines())\n",
    "\n",
    "print(chat_history)\n",
    "\n",
    "prompt = chat_template.invoke({'chat_history':chat_history, 'query':'Where is my refund'})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46709083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
