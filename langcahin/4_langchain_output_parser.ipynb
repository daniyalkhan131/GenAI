{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cace79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e0ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniyalkhan/anaconda3/envs/genAI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a 5-line summary:\n",
      "\n",
      "Black holes are regions of extreme gravity where even light becomes trapped. Formed from collapsed massive stars, they exert a powerful influence on surrounding matter and galaxies, playing a crucial role in cosmic processes.  Despite their gravitational dominance, black holes remain shrouded in secrecy with much about their nature still unknown, prompting ongoing research.  We observe them indirectly through the emission of light and gravitational waves, providing valuable insight into their behaviors. Black hole discovery pushes the boundaries of our scientific understanding and challenges our understanding of the cosmos. \n",
      "\n",
      "Let me know if you'd like any further elaboration or a different style of summary. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without string output parser\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# 1st prompt -> detailed report\n",
    "template1 = PromptTemplate(\n",
    "    template='Write a detailed report on {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "# 2nd prompt -> summary\n",
    "template2 = PromptTemplate(\n",
    "    template='Write a 5 line summary on the following text. /n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt1 = template1.invoke({'topic':'black hole'})\n",
    "\n",
    "result = model.invoke(prompt1)\n",
    "\n",
    "prompt2 = template2.invoke({'text':result.content})\n",
    "\n",
    "result1 = model.invoke(prompt2)\n",
    "\n",
    "print(result1.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c749a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black holes are regions in space with strong gravitational pull where not even light can escape, making them mysterious objects. They are formed when massive stars collapse under their own gravity or through the merger of neutron stars or black holes. Black holes have properties like mass, electric charge, and angular momentum, with different types including stellar, supermassive, and intermediate black holes. Studying black holes is crucial in astrophysics as they provide insights into the nature of spacetime, the formation and evolution of galaxies, and the birth and death of stars. Overall, black holes are enigmatic objects that challenge our understanding of the universe and help expand our knowledge of the cosmos.\n"
     ]
    }
   ],
   "source": [
    "#with string output parser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 1st prompt -> detailed report\n",
    "template1 = PromptTemplate(\n",
    "    template='Write a detailed report on {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "# 2nd prompt -> summary\n",
    "template2 = PromptTemplate(\n",
    "    template='Write a 5 line summary on the following text. /n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = template1 | model | parser | template2 | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e2e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d8d318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniyalkhan/anaconda3/envs/genAI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define the model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Give me 5 facts about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0c0423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me 5 facts about Living Water \n",
      " Return a JSON object.\n",
      "[{'fact': 'Living Water is a non-denominational Christian ministry.', 'details': 'Founded in the 1980s, Living Water is known for its focus on empowering individuals through the life-transformative teachings of Jesus Christ.'}, {'fact': 'Living Water emphasizes the importance of personal relationship with God.', 'details': 'The ministry aims to help individuals develop a deep and abiding connection with God through prayer, scripture, and spiritual guidance.'}, {'fact': 'Living Water conducts outreach programs and discipleship activities within communities.', 'details': 'To spread the message of love and salvation, Living Water engages in community service, offers workshops, and provides support to those in need.'}, {'fact': 'The Living Water movement respects all people and promotes reconciliation and unity.', 'details': 'The practice of spiritual awareness and meditation forms a shared understanding among individuals, regardless of religious background.'}, {'fact': 'Living Water offers a range of resources and information on spiritual matters.', 'details': \"From books and articles to online content and podcasts, the ministry aims to provide readers with the tools and knowledge needed to grow in God's presence.\"}]\n"
     ]
    }
   ],
   "source": [
    "prompt= template.format(topic= \"Living Water\")\n",
    "print(prompt)\n",
    "result= model.invoke(prompt)\n",
    "final_result= parser.parse(result.content)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95af9738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fact': 'Black holes are regions of spacetime where gravity is so strong that nothing, not even light, can escape.', 'category': 'Characteristics'}, {'fact': 'Black holes form when massive stars collapse at the end of their lifespans.', 'category': 'Origin'}, {'fact': 'There are various types of black holes, fromStellar-mass black holes, which are formed from the collapses of individual stars, to supermassive black holes, which reside at the centers of most galaxies.', 'category': 'Types'}, {'fact': 'The event horizon of a black hole is the point of no return, beyond which the curvature of spacetime becomes so extreme that escape is impossible.', 'category': 'Boundaries'}, {'fact': 'Black holes are not black, they emit radiation called Hawking radiation, as particles constantly interact near the event horizon.', 'category': 'Physics'}]\n"
     ]
    }
   ],
   "source": [
    "chain = template | model | parser #can also form a chain\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a282f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#structured output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe40844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fact_1': 'Black holes are regions of spacetime where gravity is so strong that nothing, not even light, can escape.', 'fact_2': 'The immense gravity of a black hole comes from the large amount of mass compressed into a tiny space.', 'fact_3': \"While we can't see black holes directly, we can detect them through their impact on surrounding matter, such as how stars orbit them.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define the model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "schema = [\n",
    "    ResponseSchema(name='fact_1', description='Fact 1 about the topic'),\n",
    "    ResponseSchema(name='fact_2', description='Fact 2 about the topic'),\n",
    "    ResponseSchema(name='fact_3', description='Fact 3 about the topic'),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Give 3 fact about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d27578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give 3 fact about Living Water \n",
      " The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"fact_1\": string  // Fact 1 about the topic\n",
      "\t\"fact_2\": string  // Fact 2 about the topic\n",
      "\t\"fact_3\": string  // Fact 3 about the topic\n",
      "}\n",
      "```\n",
      "{'fact_1': 'Living Water is a band known for its blend of acoustic folk and alternative rock genres.', 'fact_2': 'They are a Wisconsin-based band.', 'fact_3': 'They are known for their strong, emotional lyrics and captivating live performances.'}\n"
     ]
    }
   ],
   "source": [
    "prompt= template.format(topic= 'Living Water')\n",
    "print(prompt)\n",
    "result= model.invoke(prompt)\n",
    "final_result= parser.parse(result.content)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f084239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pydantic output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f886a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define the model\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "class Person(BaseModel):\n",
    "\n",
    "    name: str = Field(description='Name of the person')\n",
    "    age: int = Field(gt=18, description='Age of the person')\n",
    "    city: str = Field(description='Name of the city the person belongs to')\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Generate the name, age and city of a fictional {place} person \\n {format_instruction}',\n",
    "    input_variables=['place'],\n",
    "    partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6840013a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Generate the name, age and city of a fictional Chinese person \\n The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"Name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"description\": \"Age of the person\", \"exclusiveMinimum\": 18, \"title\": \"Age\", \"type\": \"integer\"}, \"city\": {\"description\": \"Name of the city the person belongs to\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"name\", \"age\", \"city\"]}\\n```'\n",
      "name='Lin Xiao' age=32 city='Shanghai'\n"
     ]
    }
   ],
   "source": [
    "prompt= template.invoke({'place': 'Chinese'})\n",
    "print(prompt)\n",
    "result= model.invoke(prompt)\n",
    "final_result= parser.parse(result.content)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02520e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "final_result = chain.invoke({'place':'sri lankan'})\n",
    "\n",
    "print(final_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
