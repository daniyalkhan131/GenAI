{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e856a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ef4d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f04ecf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9342b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: JokeState):\n",
    "\n",
    "    prompt = f'generate a joke on the topic {state[\"topic\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'joke': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98265dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(state: JokeState):\n",
    "\n",
    "    prompt = f'write an explanation for the joke - {state[\"joke\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'explanation': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d0e40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('generate_joke', generate_joke)\n",
    "graph.add_node('generate_explanation', generate_explanation)\n",
    "\n",
    "graph.add_edge(START, 'generate_joke')\n",
    "graph.add_edge('generate_joke', 'generate_explanation')\n",
    "graph.add_edge('generate_explanation', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e4c1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\",\n",
       " 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "workflow.invoke({'topic':'pizza'}, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03d53916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\", 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-2e5b-661e-8002-e437f167b975'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-13T02:52:34.179802+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a70a2487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\", 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-2e5b-661e-8002-e437f167b975'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-13T02:52:34.179802+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-13T02:52:31.929809+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, tasks=(PregelTask(id='35e60488-4330-3eb1-5dae-89dfe65d8101', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:52:29.526019+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, tasks=(PregelTask(id='908a0ead-e75a-9096-976c-39c03c1977b9', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-13T02:52:29.524977+00:00', parent_config=None, tasks=(PregelTask(id='5ac9e828-145b-6dfa-df46-dc083c2dccae', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8735de4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pasta',\n",
       " 'joke': 'Why did the spaghetti blush?\\n\\nBecause it saw the meatball!',\n",
       " 'explanation': 'The joke relies on a double entendre, meaning a word or phrase that has two possible interpretations, one of which is usually suggestive or humorous. Here\\'s how it works:\\n\\n* **Literal Interpretation:** Spaghetti is a type of pasta, and a meatball is a ball of ground meat often served with spaghetti. The joke personifies the spaghetti, giving it human emotions like blushing. In this context, the spaghetti is simply blushing because it is paired with the meatball, a common and perhaps pleasing accompaniment.\\n\\n* **Suggestive Interpretation:** The joke plays on the sexual innuendo of \"meatball\" being a euphemism for male genitalia. The spaghetti, in this context, is blushing because it is seeing the \"meatball\" in a romantic or suggestive way. The blushing is a reaction to the implied nudity or sexual encounter.\\n\\nThe humor comes from the unexpected and slightly naughty twist on a seemingly innocent scenario. The listener initially thinks of the literal interpretation, then the realization of the suggestive meaning creates a humorous effect.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "workflow.invoke({'topic':'pasta'}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f9e03c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\", 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-2e5b-661e-8002-e437f167b975'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-13T02:52:34.179802+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fd6803b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\", 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-2e5b-661e-8002-e437f167b975'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-13T02:52:34.179802+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-13T02:52:31.929809+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, tasks=(PregelTask(id='35e60488-4330-3eb1-5dae-89dfe65d8101', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:52:29.526019+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, tasks=(PregelTask(id='908a0ead-e75a-9096-976c-39c03c1977b9', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-13T02:52:29.524977+00:00', parent_config=None, tasks=(PregelTask(id='5ac9e828-145b-6dfa-df46-dc083c2dccae', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573bfc2",
   "metadata": {},
   "source": [
    "### Fault tolerence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4298aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import TypedDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a60d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the state\n",
    "class CrashState(TypedDict):\n",
    "    input: str\n",
    "    step1: str\n",
    "    step2: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a95e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define steps\n",
    "def step_1(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 1 executed\")\n",
    "    return {\"step1\": \"done\", \"input\": state[\"input\"]}\n",
    "\n",
    "def step_2(state: CrashState) -> CrashState:\n",
    "    print(\"⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\")\n",
    "    time.sleep(1000)  # Simulate long-running hang\n",
    "    return {\"step2\": \"done\"}\n",
    "\n",
    "def step_3(state: CrashState) -> CrashState:\n",
    "    print(\"✅ Step 3 executed\")\n",
    "    return {\"done\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b659baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build the graph\n",
    "builder = StateGraph(CrashState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "builder.set_entry_point(\"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e880b7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Running graph: Please manually interrupt during Step 2...\n",
      "✅ Step 1 executed\n",
      "⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\n",
      "❌ Kernel manually interrupted (crash simulated).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"▶️ Running graph: Please manually interrupt during Step 2...\")\n",
    "    graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "except KeyboardInterrupt:\n",
    "    print(\"❌ Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf3742f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Re-running the graph to demonstrate fault tolerance...\n",
      "⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 6. Re-run to show fault-tolerant resume\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🔁 Re-running the graph to demonstrate fault tolerance...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthread-1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Final State:\u001b[39m\u001b[38;5;124m\"\u001b[39m, final_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/main.py:3026\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3023\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3024\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   3027\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3028\u001b[0m     config,\n\u001b[1;32m   3029\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3030\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3033\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3034\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3035\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3036\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3037\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[1;32m   3038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3039\u001b[0m ):\n\u001b[1;32m   3040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3041\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/main.py:2647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2646\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2647\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2648\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2649\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2650\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2651\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2652\u001b[0m ):\n\u001b[1;32m   2653\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2654\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[1;32m   2655\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[1;32m   2656\u001b[0m     )\n\u001b[1;32m   2657\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/_internal/_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m, in \u001b[0;36mstep_2\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_2\u001b[39m(state: CrashState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrashState:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⏳ Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Simulate long-running hang\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. Re-run to show fault-tolerant resume\n",
    "print(\"\\n🔁 Re-running the graph to demonstrate fault tolerance...\")\n",
    "final_state = graph.invoke(None, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "print(\"\\n✅ Final State:\", final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf80d6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'input': 'start', 'step1': 'done'}, next=('step_2',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904b7-e9fd-6bce-8001-d274f2703928'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-13T02:43:56.983796+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904b7-e9fb-6ce8-8000-5e0964c001f9'}}, tasks=(PregelTask(id='b77c70af-fcd7-cd68-e5aa-2a08a0cf6a0b', name='step_2', path=('__pregel_pull', 'step_2'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'input': 'start'}, next=('step_1',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904b7-e9fb-6ce8-8000-5e0964c001f9'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:43:56.983005+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904b7-e9f9-6862-bfff-049cc3c456da'}}, tasks=(PregelTask(id='07f09f76-b03a-1520-1291-1cdcd4b071dd', name='step_1', path=('__pregel_pull', 'step_1'), error=None, interrupts=(), state=None, result={'step1': 'done', 'input': 'start'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904b7-e9f9-6862-bfff-049cc3c456da'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-13T02:43:56.982070+00:00', parent_config=None, tasks=(PregelTask(id='7d9f83e2-786a-93ff-613d-da97999ea37d', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'input': 'start'}),), interrupts=())]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graph.get_state_history({\"configurable\": {\"thread_id\": 'thread-1'}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb90bb62",
   "metadata": {},
   "source": [
    "### Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2561bf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3575b9e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyInputError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1f06cc6e-7232-6cb1-8000-f71609e6cec5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/main.py:3026\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3023\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3024\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   3027\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3028\u001b[0m     config,\n\u001b[1;32m   3029\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3030\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3033\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3034\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3035\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3036\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3037\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[1;32m   3038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3039\u001b[0m ):\n\u001b[1;32m   3040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3041\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/main.py:2582\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2579\u001b[0m runtime \u001b[38;5;241m=\u001b[39m parent_runtime\u001b[38;5;241m.\u001b[39mmerge(runtime)\n\u001b[1;32m   2580\u001b[0m config[CONF][CONFIG_KEY_RUNTIME] \u001b[38;5;241m=\u001b[39m runtime\n\u001b[0;32m-> 2582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SyncPregelLoop(\n\u001b[1;32m   2583\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2584\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput, stream_modes),\n\u001b[1;32m   2585\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m   2586\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[1;32m   2587\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   2588\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[1;32m   2589\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[1;32m   2590\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m   2591\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2592\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   2593\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[1;32m   2594\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   2595\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   2596\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   2597\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability_,\n\u001b[1;32m   2598\u001b[0m     trigger_to_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_to_nodes,\n\u001b[1;32m   2599\u001b[0m     migrate_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_migrate_checkpoint,\n\u001b[1;32m   2600\u001b[0m     retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2601\u001b[0m     cache_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_policy,\n\u001b[1;32m   2602\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[1;32m   2603\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[1;32m   2605\u001b[0m         submit\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   2606\u001b[0m             CONFIG_KEY_RUNNER_SUBMIT, weakref\u001b[38;5;241m.\u001b[39mWeakMethod(loop\u001b[38;5;241m.\u001b[39msubmit)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2609\u001b[0m         node_finished\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_NODE_FINISHED),\n\u001b[1;32m   2610\u001b[0m     )\n\u001b[1;32m   2611\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/_loop.py:1044\u001b[0m, in \u001b[0;36mSyncPregelLoop.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_previous_versions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdated_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdated_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdated_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/_loop.py:670\u001b[0m, in \u001b[0;36mPregelLoop._first\u001b[0;34m(self, input_keys, updated_channels)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_put_checkpoint({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_nested:\n",
      "\u001b[0;31mEmptyInputError\u001b[0m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e73ced1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\", 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-2e5b-661e-8002-e437f167b975'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-13T02:52:34.179802+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-13T02:52:31.929809+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, tasks=(PregelTask(id='35e60488-4330-3eb1-5dae-89dfe65d8101', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:52:29.526019+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, tasks=(PregelTask(id='908a0ead-e75a-9096-976c-39c03c1977b9', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-13T02:52:29.524977+00:00', parent_config=None, tasks=(PregelTask(id='5ac9e828-145b-6dfa-df46-dc083c2dccae', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1da08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0063f68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0904cc-a002-6514-8000-9eadef79dc61'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.update_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\", \"checkpoint_ns\": \"\"}}, {'topic':'samosa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "731690fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cc-a002-6514-8000-9eadef79dc61'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:53:12.940667+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, tasks=(PregelTask(id='fb7de499-9283-6e02-01c8-5971b36c7b7a', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\", 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-2e5b-661e-8002-e437f167b975'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-13T02:52:34.179802+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-13T02:52:31.929809+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, tasks=(PregelTask(id='35e60488-4330-3eb1-5dae-89dfe65d8101', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:52:29.526019+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, tasks=(PregelTask(id='908a0ead-e75a-9096-976c-39c03c1977b9', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-13T02:52:29.524977+00:00', parent_config=None, tasks=(PregelTask(id='5ac9e828-145b-6dfa-df46-dc083c2dccae', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0acb9d55",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyInputError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoint_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1f06cc72-ca16-6359-8001-7eea05e07dd2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/main.py:3026\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3023\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3024\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 3026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   3027\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3028\u001b[0m     config,\n\u001b[1;32m   3029\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m   3030\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   3033\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   3034\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   3035\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   3036\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   3037\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[1;32m   3038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3039\u001b[0m ):\n\u001b[1;32m   3040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3041\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/main.py:2582\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2579\u001b[0m runtime \u001b[38;5;241m=\u001b[39m parent_runtime\u001b[38;5;241m.\u001b[39mmerge(runtime)\n\u001b[1;32m   2580\u001b[0m config[CONF][CONFIG_KEY_RUNTIME] \u001b[38;5;241m=\u001b[39m runtime\n\u001b[0;32m-> 2582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SyncPregelLoop(\n\u001b[1;32m   2583\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2584\u001b[0m     stream\u001b[38;5;241m=\u001b[39mStreamProtocol(stream\u001b[38;5;241m.\u001b[39mput, stream_modes),\n\u001b[1;32m   2585\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m   2586\u001b[0m     store\u001b[38;5;241m=\u001b[39mstore,\n\u001b[1;32m   2587\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[1;32m   2588\u001b[0m     checkpointer\u001b[38;5;241m=\u001b[39mcheckpointer,\n\u001b[1;32m   2589\u001b[0m     nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes,\n\u001b[1;32m   2590\u001b[0m     specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m   2591\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2592\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   2593\u001b[0m     stream_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_channels_asis,\n\u001b[1;32m   2594\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   2595\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   2596\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   2597\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability_,\n\u001b[1;32m   2598\u001b[0m     trigger_to_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_to_nodes,\n\u001b[1;32m   2599\u001b[0m     migrate_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_migrate_checkpoint,\n\u001b[1;32m   2600\u001b[0m     retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2601\u001b[0m     cache_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_policy,\n\u001b[1;32m   2602\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[1;32m   2603\u001b[0m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m     runner \u001b[38;5;241m=\u001b[39m PregelRunner(\n\u001b[1;32m   2605\u001b[0m         submit\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   2606\u001b[0m             CONFIG_KEY_RUNNER_SUBMIT, weakref\u001b[38;5;241m.\u001b[39mWeakMethod(loop\u001b[38;5;241m.\u001b[39msubmit)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2609\u001b[0m         node_finished\u001b[38;5;241m=\u001b[39mconfig[CONF]\u001b[38;5;241m.\u001b[39mget(CONFIG_KEY_NODE_FINISHED),\n\u001b[1;32m   2610\u001b[0m     )\n\u001b[1;32m   2611\u001b[0m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/_loop.py:1044\u001b[0m, in \u001b[0;36mSyncPregelLoop.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_previous_versions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdated_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdated_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdated_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupdated_channels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/genAI/lib/python3.10/site-packages/langgraph/pregel/_loop.py:670\u001b[0m, in \u001b[0;36mPregelLoop._first\u001b[0;34m(self, input_keys, updated_channels)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_put_checkpoint({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_nested:\n",
      "\u001b[0;31mEmptyInputError\u001b[0m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc72-ca16-6359-8001-7eea05e07dd2\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "972aa030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cc-a002-6514-8000-9eadef79dc61'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:53:12.940667+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, tasks=(PregelTask(id='fb7de499-9283-6e02-01c8-5971b36c7b7a', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\", 'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-2e5b-661e-8002-e437f167b975'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-09-13T02:52:34.179802+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-18e6-63d8-8001-1c918ba29128'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-09-13T02:52:31.929809+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, tasks=(PregelTask(id='35e60488-4330-3eb1-5dae-89dfe65d8101', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'The joke \"Why did the pizza maker quit his job? Because he was tired of getting into so many arguments... he just couldn\\'t stand the topping!\" is a pun. Here\\'s the breakdown:\\n\\n* **The Setup:** The setup leads you to believe the pizza maker quit because of some work-related stress or conflict. The phrase \"arguments\" suggests heated debates or disagreements.\\n\\n* **The Pun:** The punchline plays on the double meaning of the word \"topping.\"\\n    * **Literal Meaning:** \"Topping\" refers to the ingredients placed on top of a pizza, like pepperoni, mushrooms, or cheese.\\n    * **Figurative Meaning:** \"Topping\" sounds like \"top-ping,\" which is a verb meaning \"to surpass\" or \"to be better than.\" The pizza maker \"can\\'t stand\" the toppings because they are better than them.\\n\\n* **The Humor:** The humor comes from the unexpected twist. Instead of the pizza maker arguing with coworkers or customers, he\\'s arguing with the *pizza toppings* themselves, or he feels that the toppings are better than him. The joke uses the literal meaning of \"topping\" to create a silly and absurd situation.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f9-6878-8000-c273358e59b0'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-09-13T02:52:29.526019+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, tasks=(PregelTask(id='908a0ead-e75a-9096-976c-39c03c1977b9', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza maker quit his job?\\n\\nBecause he was tired of getting into so many arguments... he just couldn't stand the topping!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0904cb-01f6-6f9c-bfff-b03958c3fe3f'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-09-13T02:52:29.524977+00:00', parent_config=None, tasks=(PregelTask(id='5ac9e828-145b-6dfa-df46-dc083c2dccae', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93372d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
